# Research-Paper-Abstract-Sentiment-Analysis-By-Machine-Learning-
<!DOCTYPE html>
<html lang="en">
<head>
<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">

<body>

<header>
<h1>Research Abstract Sentiment Analysis</h1>
<p>Machine Learning â†’ Deep Learning â†’ Transformer (NLP Project)</p>
</header>

<section>
<h2>ğŸ“Œ Project Overview</h2>
<p>
This project implements an automated system to analyze the sentiment of research
paper abstracts using Natural Language Processing (NLP). Abstracts are classified
into <strong>Positive</strong>, <strong>Neutral</strong>, or <strong>Negative</strong>
categories to assist researchers during literature review and analysis.
</p>
</section>

<section>
<h2>ğŸ¯ Objectives</h2>
<ul>
<li>Automate sentiment analysis of academic abstracts</li>
<li>Compare classical ML, deep learning, and transformer models</li>
<li>Analyze model behavior using confusion matrices and graphs</li>
<li>Deploy a real-time sentiment analysis web application</li>
</ul>
</section>

<section>
<h2>ğŸ§  Models Implemented (Model Evolution)</h2>

<h3>1ï¸âƒ£ Logistic Regression (TF-IDF) â€“ Machine Learning</h3>
<ul>
<li>Traditional NLP pipeline using TF-IDF feature extraction</li>
<li>Interpretable and efficient baseline model</li>
<li>Accuracy â‰ˆ 72%</li>
</ul>

<h3>2ï¸âƒ£ Random Forest (TF-IDF) â€“ Ensemble ML</h3>
<ul>
<li>Tree-based ensemble classifier</li>
<li>Captures non-linear patterns</li>
<li>Accuracy â‰ˆ 73%</li>
</ul>

<h3>3ï¸âƒ£ LSTM â€“ Deep Learning</h3>
<ul>
<li>Sequence-based neural network using word embeddings</li>
<li>Trained to capture contextual dependencies in abstracts</li>
<li>Accuracy â‰ˆ 68%</li>
</ul>

<p>
Although the LSTM achieved reasonable accuracy, class-wise evaluation revealed
strong bias toward the majority class due to class imbalance introduced by
automatic sentiment labeling. This demonstrates the limitations of deep learning
models on imbalanced datasets.
</p>

<h3>4ï¸âƒ£ BERT â€“ Transformer Model</h3>
<ul>
<li>Pretrained transformer-based NLP model</li>
<li>Context-aware sentiment understanding</li>
<li>Accuracy â‰ˆ 80â€“85%</li>
<li>Used in deployed application</li>
</ul>
</section>

<section>
<h2>ğŸ—ï¸ System Architecture</h2>
<pre>
User Input (Abstract)
        â†“
Text Preprocessing
        â†“
Feature Representation
   â”œâ”€ TF-IDF Vectorization
   â”œâ”€ Word Embeddings (LSTM)
   â””â”€ BERT Tokenization
        â†“
Model Prediction
        â†“
Sentiment Output
        â†“
Visualization & Export
</pre>
</section>

<section>
<h2>ğŸ“Š Evaluation & Results</h2>

<h3>Logistic Regression â€“ Confusion Matrix</h3>
<img src="output.png" alt="Logistic Regression Confusion Matrix">
<figcaption>Figure 1: Confusion Matrix â€“ Logistic Regression</figcaption>

<h3>Random Forest â€“ Confusion Matrix</h3>
<img src="outpu1t.png" alt="Random Forest Confusion Matrix">
<figcaption>Figure 2: Confusion Matrix â€“ Random Forest</figcaption>

<h3>LSTM â€“ Confusion Matrix</h3>
<img src="output4.png" alt="LSTM Confusion Matrix">
<figcaption>Figure 3: Confusion Matrix â€“ LSTM (Majority Class Bias)</figcaption>

<h3>LSTM Training Performance</h3>
<img src="output5.png" alt="LSTM Accuracy Curve">
<figcaption>Figure 4: LSTM Training vs Validation Accuracy</figcaption>

<img src="output6.png" alt="LSTM Loss Curve">
<figcaption>Figure 5: LSTM Training vs Validation Loss</figcaption>

<h3>Model Accuracy Comparison</h3>
<img src="output3.png" alt="Model Accuracy Comparison">
<figcaption>Figure 6: Accuracy Comparison â€“ ML vs LSTM vs BERT</figcaption>
</section>
<section>
<h2>ğŸ—ï¸ System Architecture</h2>

<p>
The Research Abstract Sentiment Analysis system follows a modular and layered
architecture. Each stage of the pipeline is independent, allowing multiple
NLP models to be evaluated and compared efficiently.
</p>

<pre>
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        User Interface         â”‚
â”‚     (Streamlit Web App)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Input Layer            â”‚
â”‚  Research Abstract / CSV File â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Text Preprocessing        â”‚
â”‚ â€¢ Lowercasing                 â”‚
â”‚ â€¢ Stopword Removal            â”‚
â”‚ â€¢ Noise & Symbol Cleaning     â”‚
â”‚ â€¢ Tokenization                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Feature Representation Layer          â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚  TF-IDF Vectors  â”‚  â”‚  Word Embeddings â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚              â”‚     BERT Tokenization     â”‚  â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Model Selection Layer               â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Logistic Reg.    â”‚ â”‚ Random Forest     â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚           â”‚            LSTM             â”‚  â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚           â”‚            BERT             â”‚  â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Sentiment Prediction      â”‚
â”‚  Positive / Neutral / Negativeâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Visualization & Reporting    â”‚
â”‚ â€¢ Confusion Matrix            â”‚
â”‚ â€¢ Accuracy & Loss Graphs      â”‚
â”‚ â€¢ CSV / PDF / Word Export     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</pre>

<p>
For deployment, lightweight models (Logistic Regression and BERT) are integrated
into the Streamlit application. The LSTM model is included for academic evaluation
and comparison but is not deployed due to computational constraints.
</p>

</section>

<section>
<h2>ğŸš€ Deployment</h2>
<p>
The application is deployed using <strong>Streamlit Cloud</strong>.
For deployment stability, only Logistic Regression and BERT models are used.
The LSTM model is included for academic comparison and analysis but is not deployed
due to computational and dependency constraints.
</p>

<p>
<strong>Live App:</strong><br>
<a href="https://cuoaoxdqzbdfqghkjmhw22.streamlit.app/" target="_blank">
https://cuoaoxdqzbdfqghkjmhw22.streamlit.app/
</a>
</p>
</section>

<section>
<h2>ğŸ› ï¸ Technologies Used</h2>
<ul>
<li>Python</li>
<li>NLTK, TF-IDF</li>
<li>Scikit-learn</li>
<li>TensorFlow (LSTM)</li>
<li>Hugging Face Transformers</li>
<li>PyTorch</li>
<li>Streamlit</li>
<li>Matplotlib, Seaborn</li>
</ul>
</section>

<section>
<h2>ğŸ”® Future Scope</h2>
<ul>
<li>Balanced and human-labeled sentiment datasets</li>
<li>SciBERT-based sentiment classification</li>
<li>Retrieval-Augmented Generation (RAG) for explanations</li>
<li>Full research paper PDF analysis</li>
</ul>
</section>

<section>
<h2>ğŸ‘©â€ğŸ’» Author</h2>
<p>
  
<strong>Sparshi Jain</strong><br>
thanks
B.Tech â€“ Mathematics & Computing<br>
Minor Project â€“ Machine Learning & NLP
</p>
</section>

<footer>
<p>Â© 2025 Research Abstract Sentiment Analysis</p>
</footer>

</body>
</html>

  







